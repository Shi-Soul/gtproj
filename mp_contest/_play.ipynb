{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import ray\n",
    "from torch import nn\n",
    "\n",
    "from typing import *\n",
    "from ray import air\n",
    "from ray import tune\n",
    "from baselines.train.configs import get_experiment_config\n",
    "from ray.rllib.algorithms import ppo\n",
    "from ray.tune import registry\n",
    "from ray.air.integrations.wandb import WandbLoggerCallback\n",
    "from baselines.train import make_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckp = \"results/torch/pd_matrix/PPO_meltingpot_397b4_00000_0_2024-05-21_13-58-39/checkpoint_007270\"\n",
    "\n",
    "registry.register_env(\"meltingpot\", make_envs.env_creator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 07:04:37,880\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2024-05-24 07:04:37,882\tWARNING algorithm_config.py:2548 -- Setting `exploration_config={'type': 'StochasticSampling'}` because you set `_enable_rl_module_api=False`. This exploration config was restored from a prior exploration config that was overriden when setting `_enable_rl_module_api=True`. This occurs because when RLModule API are enabled, exploration_config can not be set.\n",
      "2024-05-24 07:04:37,885\tWARNING algorithm_config.py:656 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "2024-05-24 07:04:37,898\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-05-24 07:04:41,806\tINFO worker.py:1612 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(pid=4055641)\u001b[0m 2024-05-24 07:04:51.351999: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/cv2/../../lib64:/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/cv2/../../lib64::/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/cuda/bin:/usr/local/cuda/bin\n",
      "\u001b[2m\u001b[36m(pid=4055627)\u001b[0m 2024-05-24 07:04:53.560726: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[2m\u001b[36m(pid=4055631)\u001b[0m 2024-05-24 07:04:56.521894: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/cv2/../../lib64:/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/cv2/../../lib64::/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/cuda/bin:/usr/local/cuda/bin\u001b[32m [repeated 107x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=4055628)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=4055688)\u001b[0m 2024-05-24 07:04:57.628254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=4055688)\u001b[0m 2024-05-24 07:04:57.628223: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/cv2/../../lib64:/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/cv2/../../lib64::/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/cuda/bin:/usr/local/cuda/bin\u001b[32m [repeated 72x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=4055628)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=4055663)\u001b[0m \u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=4055638)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m /NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m 2024-05-24 07:05:16,832\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m 2024-05-24 07:05:17,063\tINFO policy.py:1294 -- Policy (worker=5) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m 2024-05-24 07:05:17,064\tINFO torch_policy_v2.py:113 -- Found 0 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m 2024-05-24 07:05:17,127\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m 2024-05-24 07:05:17,148\tINFO policy.py:1294 -- Policy (worker=5) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m 2024-05-24 07:05:17,148\tINFO torch_policy_v2.py:113 -- Found 0 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m 2024-05-24 07:05:17,172\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m 2024-05-24 07:05:17,173\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m         StateBufferConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m 2024-05-24 07:05:17,173\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m 2024-05-24 07:05:17,173\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m 2024-05-24 07:05:17,173\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m         StateBufferConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m 2024-05-24 07:05:17,173\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055628)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055624)\u001b[0m 2024-05-24 07:05:17,376\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.tf.recurrent_net.LSTMWrapper` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055624)\u001b[0m 2024-05-24 07:05:17,376\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.complex_input_net.ComplexInputNetwork` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055624)\u001b[0m 2024-05-24 07:05:17,376\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055624)\u001b[0m 2024-05-24 07:05:17,377\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055624)\u001b[0m 2024-05-24 07:05:17,419\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.visionnet.VisionNetwork` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055624)\u001b[0m 2024-05-24 07:05:17,436\tWARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055624)\u001b[0m 2024-05-24 07:05:17,436\tWARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055624)\u001b[0m 2024-05-24 07:05:17,437\tWARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055624)\u001b[0m 2024-05-24 07:05:17,439\tWARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055624)\u001b[0m 2024-05-24 07:05:17,439\tWARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055624)\u001b[0m 2024-05-24 07:05:17,439\tWARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055624)\u001b[0m 2024-05-24 07:05:17,439\tWARNING deprecation.py:50 -- DeprecationWarning: `KLCoeffMixin` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055624)\u001b[0m 2024-05-24 07:05:17,447\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.recurrent_net.RecurrentNetwork` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055624)\u001b[0m 2024-05-24 07:05:17,478\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=4055652)\u001b[0m \u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=4055652)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055640)\u001b[0m /NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055640)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055640)\u001b[0m 2024-05-24 07:05:21,800\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055653)\u001b[0m 2024-05-24 07:05:22,153\tINFO policy.py:1294 -- Policy (worker=29) running on CPU.\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055653)\u001b[0m 2024-05-24 07:05:22,153\tINFO torch_policy_v2.py:113 -- Found 0 visible cuda devices.\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055653)\u001b[0m 2024-05-24 07:05:22,179\tINFO util.py:118 -- Using connectors:\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055653)\u001b[0m 2024-05-24 07:05:22,179\tINFO util.py:119 --     AgentConnectorPipeline\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055653)\u001b[0m         StateBufferConnector\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055653)\u001b[0m         ViewRequirementAgentConnector\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055653)\u001b[0m 2024-05-24 07:05:22,179\tINFO util.py:120 --     ActionConnectorPipeline\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055653)\u001b[0m         ConvertToNumpyConnector\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055653)\u001b[0m         NormalizeActionsConnector\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4055653)\u001b[0m         ImmutableActionsConnector\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "2024-05-24 07:05:23,682\tINFO worker_set.py:297 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'INVENTORY': Box(-inf, inf, (2,), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (5, 5, 3), uint8)), Discrete(8)), 'agent_0': (Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'INVENTORY': Box(-inf, inf, (2,), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (5, 5, 3), uint8)), Discrete(8)), '__env__': (Dict('player_0': Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'INVENTORY': Box(-inf, inf, (2,), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (5, 5, 3), uint8)), 'player_1': Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'INVENTORY': Box(-inf, inf, (2,), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (5, 5, 3), uint8))), Dict('player_0': Discrete(8), 'player_1': Discrete(8)))}\n",
      "2024-05-24 07:05:23,970\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2024-05-24 07:05:23,990\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.tf.recurrent_net.LSTMWrapper` has been deprecated. This will raise an error in the future!\n",
      "2024-05-24 07:05:23,992\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.complex_input_net.ComplexInputNetwork` has been deprecated. This will raise an error in the future!\n",
      "2024-05-24 07:05:23,993\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!\n",
      "2024-05-24 07:05:23,995\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!\n",
      "2024-05-24 07:05:24,088\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.visionnet.VisionNetwork` has been deprecated. This will raise an error in the future!\n",
      "2024-05-24 07:05:24,121\tINFO policy.py:1294 -- Policy (worker=local) running on CPU.\n",
      "2024-05-24 07:05:24,122\tINFO torch_policy_v2.py:113 -- Found 1 visible cuda devices.\n",
      "2024-05-24 07:05:24,128\tWARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!\n",
      "2024-05-24 07:05:24,129\tWARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!\n",
      "2024-05-24 07:05:24,130\tWARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!\n",
      "2024-05-24 07:05:24,133\tWARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!\n",
      "2024-05-24 07:05:24,134\tWARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!\n",
      "2024-05-24 07:05:24,135\tWARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!\n",
      "2024-05-24 07:05:24,136\tWARNING deprecation.py:50 -- DeprecationWarning: `KLCoeffMixin` has been deprecated. This will raise an error in the future!\n",
      "2024-05-24 07:05:24,147\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.recurrent_net.RecurrentNetwork` has been deprecated. This will raise an error in the future!\n",
      "2024-05-24 07:05:24,182\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!\n",
      "2024-05-24 07:05:24,217\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2024-05-24 07:05:24,241\tINFO policy.py:1294 -- Policy (worker=local) running on CPU.\n",
      "2024-05-24 07:05:24,243\tINFO torch_policy_v2.py:113 -- Found 1 visible cuda devices.\n",
      "2024-05-24 07:05:24,273\tINFO util.py:118 -- Using connectors:\n",
      "2024-05-24 07:05:24,274\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2024-05-24 07:05:24,275\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2024-05-24 07:05:24,278\tINFO util.py:118 -- Using connectors:\n",
      "2024-05-24 07:05:24,279\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2024-05-24 07:05:24,280\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2024-05-24 07:05:24,281\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_1', 'agent_0']>\n",
      "2024-05-24 07:05:24,282\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2024-05-24 07:05:24,283\tINFO rollout_worker.py:550 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2024-05-24 07:05:24,663\tINFO trainable.py:172 -- Trainable.setup took 46.697 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2024-05-24 07:05:24,668\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "2024-05-24 07:05:25,247\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2024-05-24 07:05:25,249\tWARNING algorithm_config.py:2548 -- Setting `exploration_config={'type': 'StochasticSampling'}` because you set `_enable_rl_module_api=False`. This exploration config was restored from a prior exploration config that was overriden when setting `_enable_rl_module_api=True`. This occurs because when RLModule API are enabled, exploration_config can not be set.\n",
      "2024-05-24 07:05:25,620\tINFO trainable.py:904 -- Restored on 10.0.3.43 from checkpoint: results/torch/pd_matrix/PPO_meltingpot_397b4_00000_0_2024-05-21_13-58-39/checkpoint_007270\n",
      "2024-05-24 07:05:25,621\tINFO trainable.py:913 -- Current state after restoring: {'_iteration': 7270, '_timesteps_total': None, '_time_total': 44642.54804444313, '_episodes_total': 1452}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing training from results/torch/pd_matrix/PPO_meltingpot_397b4_00000_0_2024-05-21_13-58-39/checkpoint_007270\n"
     ]
    }
   ],
   "source": [
    "# del trainer\n",
    "trainer:ppo.PPO = ppo.PPO.from_checkpoint(ckp)\n",
    "trainer.restore(ckp)\n",
    "print(f\"Continuing training from {ckp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO\n",
      "['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__ray_actor_class__', '__ray_ready__', '__ray_terminate__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_allow_unknown_configs', '_allow_unknown_subkeys', '_annotated', '_automatic_evaluation_duration_fn', '_before_evaluate', '_checkpoint_cls', '_checkpoint_info_to_algorithm_state', '_close_logfiles', '_compile_iteration_results', '_counters', '_create_checkpoint_dir', '_create_local_replay_buffer_if_necessary', '_create_logger', '_env_id', '_episode_history', '_episodes_to_be_collected', '_episodes_total', '_evaluate_async', '_export_model', '_get_env_id_and_creator', '_get_latest_available_checkpoint', '_get_latest_local_available_checkpoint', '_get_latest_remote_available_checkpoint', '_get_learner_bundles', '_implements_method', '_init', '_iteration', '_iterations_since_restore', '_kwargs_for_execution_plan', '_last_artifact_sync_iter', '_last_result', '_local_ip', '_logdir', '_maybe_load_artifacts_from_cloud', '_maybe_load_checkpoint_from_cloud', '_maybe_load_from_cloud', '_maybe_save_artifacts_to_cloud', '_maybe_save_to_cloud', '_monitor', '_open_logfiles', '_override_all_key_list', '_override_all_subkeys_if_type_changes', '_progress_metrics', '_record_usage', '_remote_storage_path', '_remote_worker_ids_for_metrics', '_restore_from_checkpoint_obj', '_restored', '_result_logger', '_run_offline_evaluation', '_run_one_evaluation', '_run_one_training_iteration', '_run_one_training_iteration_and_evaluation_in_parallel', '_should_create_evaluation_rollout_workers', '_should_upload_artifacts', '_start_time', '_stderr_context', '_stderr_file', '_stderr_fp', '_stderr_logging_handler', '_stderr_stream', '_stdout_context', '_stdout_file', '_stdout_fp', '_stdout_stream', '_sync_filters_if_needed', '_sync_weights_to_workers', '_time_since_restore', '_time_total', '_timers', '_timesteps_since_restore', '_timesteps_total', '_trial_info', 'add_policy', 'callbacks', 'cleanup', 'compute_actions', 'compute_single_action', 'config', 'default_resource_request', 'delete_checkpoint', 'env_creator', 'evaluate', 'evaluation_config', 'evaluation_dataset', 'evaluation_metrics', 'evaluation_workers', 'execution_plan', 'export_model', 'export_policy_checkpoint', 'export_policy_model', 'from_checkpoint', 'from_state', 'get_auto_filled_metrics', 'get_config', 'get_current_ip_pid', 'get_default_config', 'get_default_policy_class', 'get_policy', 'get_state', 'get_weights', 'import_model', 'import_policy_model_from_h5', 'is_actor', 'iteration', 'learner_group', 'load_checkpoint', 'local_replay_buffer', 'log_result', 'logdir', 'merge_algorithm_configs', 'remote_checkpoint_dir', 'remote_requests_in_flight', 'remove_policy', 'reset', 'reset_config', 'resource_help', 'restore', 'restore_from_object', 'restore_workers', 'reward_estimators', 'save', 'save_checkpoint', 'save_to_object', 'set_weights', 'setup', 'step', 'stop', 'sync_config', 'sync_num_retries', 'sync_sleep_time', 'train', 'train_buffered', 'train_exec_impl', 'training_iteration', 'training_step', 'trial_id', 'trial_name', 'trial_resources', 'uses_cloud_checkpointing', 'validate_config', 'validate_env', 'workers']\n",
      "{'_env_id': 'meltingpot', 'env_creator': <function env_creator at 0x7f208ad423b0>, 'local_replay_buffer': None, '_timers': defaultdict(<class 'ray.util.timer._Timer'>, {}), '_counters': defaultdict(<class 'int'>, {'num_env_steps_sampled': 2908000, 'num_env_steps_trained': 2908000, 'num_agent_steps_sampled': 5816000, 'num_agent_steps_trained': 5816000}), '_episode_history': [], '_episodes_to_be_collected': [], 'evaluation_config': <ray.rllib.algorithms.ppo.ppo.PPOConfig object at 0x7f22c45e1840>, 'evaluation_workers': None, 'evaluation_metrics': {'evaluation': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan}}}, 'config': <ray.rllib.algorithms.ppo.ppo.PPOConfig object at 0x7f2089dfc400>, '_result_logger': <ray.tune.logger.unified.UnifiedLogger object at 0x7f2089e78130>, '_logdir': '/home/wjxie/ray_results/PPO_meltingpot_2024-05-24_07-04-37mgubajrs', '_stdout_context': None, '_stdout_fp': None, '_stdout_stream': None, '_stderr_context': None, '_stderr_fp': None, '_stderr_stream': None, '_stderr_logging_handler': None, '_iteration': 7270, '_time_total': 44642.54804444313, '_timesteps_total': None, '_episodes_total': 1452, '_time_since_restore': 0.0, '_timesteps_since_restore': 0, '_iterations_since_restore': 0, '_last_result': None, '_restored': True, '_trial_info': None, '_stdout_file': None, '_stderr_file': None, '_start_time': 1716534277.9662387, '_local_ip': '10.0.3.43', 'callbacks': <ray.rllib.algorithms.callbacks.DefaultCallbacks object at 0x7f2089d3dff0>, 'remote_requests_in_flight': defaultdict(<class 'set'>, {}), 'workers': <ray.rllib.evaluation.worker_set.WorkerSet object at 0x7f2089d3e0e0>, 'train_exec_impl': None, 'evaluation_dataset': None, 'reward_estimators': {}, 'learner_group': None, '_monitor': <UtilMonitor(Thread-5, started daemon 139782292178688)>, 'remote_checkpoint_dir': None, 'sync_config': SyncConfig(upload_dir=None, syncer=None, sync_period=300, sync_timeout=1800, sync_artifacts=True, sync_on_checkpoint=True), 'sync_num_retries': 3, 'sync_sleep_time': 1.0, '_last_artifact_sync_iter': None}\n"
     ]
    }
   ],
   "source": [
    "print(trainer)\n",
    "print(dir(trainer))\n",
    "print(trainer.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__class__', '__del__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_annotated', '_build_policy_map', '_call_callbacks_on_create_policy', '_ds_shards', '_get_complete_policy_specs_dict', '_get_input_creator_from_config', '_get_make_sub_env_fn', '_get_output_creator_from_config', '_lock', '_original_kwargs', '_update_filter_dict', '_update_policy_dict_with_marl_module', '_update_policy_map', 'add_policy', 'apply', 'apply_gradients', 'assert_healthy', 'async_env', 'callbacks', 'compute_gradients', 'config', 'creation_args', 'default_policy_class', 'env', 'env_context', 'env_creator', 'filters', 'find_free_port', 'for_policy', 'foreach_env', 'foreach_env_with_context', 'foreach_policy', 'foreach_policy_to_train', 'get_filters', 'get_global_vars', 'get_host', 'get_metrics', 'get_node_ip', 'get_policies_to_train', 'get_policy', 'get_state', 'get_weights', 'global_vars', 'input_reader', 'io_context', 'is_policy_to_train', 'item_generator', 'last_batch', 'learn_on_batch', 'local_it', 'lock', 'make_sub_env_fn', 'marl_module_spec', 'multiagent', 'next_ith_buffer', 'num_workers', 'output_writer', 'par_iter_init', 'par_iter_next', 'par_iter_next_batch', 'par_iter_slice', 'par_iter_slice_batch', 'ping', 'policy_dict', 'policy_map', 'policy_mapping_fn', 'preprocessing_enabled', 'preprocessors', 'recreated_worker', 'remove_policy', 'sample', 'sample_and_learn', 'sample_with_count', 'sampler', 'seed', 'set_global_vars', 'set_is_policy_to_train', 'set_policy_mapping_fn', 'set_state', 'set_weights', 'setup_torch_data_parallel', 'spaces', 'stop', 'sync_filters', 'total_rollout_fragment_length', 'transforms', 'unlock', 'weights_seq_no', 'worker_index']\n",
      "Total_params:  113932\n",
      "odict_keys(['cnns', 'one_hot', 'flatten', 'flatten_0', 'flatten_1', 'flatten_2', 'cnn_3', 'post_fc_stack', 'lstm', '_logits_branch', '_value_branch'])\n",
      "ComplexInputNetwork_as_LSTMWrapper(\n",
      "  (cnns): ModuleDict(\n",
      "    (3): VisionNetwork(\n",
      "      (_convs): Sequential(\n",
      "        (0): SlimConv2d(\n",
      "          (_model): Sequential(\n",
      "            (0): ZeroPad2d((3, 4, 3, 4))\n",
      "            (1): Conv2d(3, 16, kernel_size=(8, 8), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): SlimConv2d(\n",
      "          (_model): Sequential(\n",
      "            (0): Conv2d(16, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "            (1): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (2): Flatten(start_dim=1, end_dim=-1)\n",
      "      )\n",
      "      (_value_branch_separate): Sequential(\n",
      "        (0): SlimConv2d(\n",
      "          (_model): Sequential(\n",
      "            (0): ZeroPad2d((3, 4, 3, 4))\n",
      "            (1): Conv2d(3, 16, kernel_size=(8, 8), stride=(1, 1))\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): SlimConv2d(\n",
      "          (_model): Sequential(\n",
      "            (0): Conv2d(16, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "            (1): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (2): SlimConv2d(\n",
      "          (_model): Sequential(\n",
      "            (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (one_hot): ModuleDict()\n",
      "  (flatten): ModuleDict(\n",
      "    (0): FullyConnectedNetwork(\n",
      "      (_hidden_layers): Sequential(\n",
      "        (0): SlimFC(\n",
      "          (_model): Sequential(\n",
      "            (0): Linear(in_features=1, out_features=4, bias=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): SlimFC(\n",
      "          (_model): Sequential(\n",
      "            (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (_value_branch_separate): Sequential(\n",
      "        (0): SlimFC(\n",
      "          (_model): Sequential(\n",
      "            (0): Linear(in_features=1, out_features=4, bias=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): SlimFC(\n",
      "          (_model): Sequential(\n",
      "            (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (_value_branch): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=4, out_features=1, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): FullyConnectedNetwork(\n",
      "      (_hidden_layers): Sequential(\n",
      "        (0): SlimFC(\n",
      "          (_model): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): SlimFC(\n",
      "          (_model): Sequential(\n",
      "            (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (_value_branch_separate): Sequential(\n",
      "        (0): SlimFC(\n",
      "          (_model): Sequential(\n",
      "            (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): SlimFC(\n",
      "          (_model): Sequential(\n",
      "            (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (_value_branch): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=4, out_features=1, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): FullyConnectedNetwork(\n",
      "      (_hidden_layers): Sequential(\n",
      "        (0): SlimFC(\n",
      "          (_model): Sequential(\n",
      "            (0): Linear(in_features=1, out_features=4, bias=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): SlimFC(\n",
      "          (_model): Sequential(\n",
      "            (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (_value_branch_separate): Sequential(\n",
      "        (0): SlimFC(\n",
      "          (_model): Sequential(\n",
      "            (0): Linear(in_features=1, out_features=4, bias=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): SlimFC(\n",
      "          (_model): Sequential(\n",
      "            (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (_value_branch): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=4, out_features=1, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (flatten_0): FullyConnectedNetwork(\n",
      "    (_hidden_layers): Sequential(\n",
      "      (0): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=1, out_features=4, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_value_branch_separate): Sequential(\n",
      "      (0): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=1, out_features=4, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_value_branch): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (flatten_1): FullyConnectedNetwork(\n",
      "    (_hidden_layers): Sequential(\n",
      "      (0): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_value_branch_separate): Sequential(\n",
      "      (0): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_value_branch): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (flatten_2): FullyConnectedNetwork(\n",
      "    (_hidden_layers): Sequential(\n",
      "      (0): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=1, out_features=4, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_value_branch_separate): Sequential(\n",
      "      (0): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=1, out_features=4, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_value_branch): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (cnn_3): VisionNetwork(\n",
      "    (_convs): Sequential(\n",
      "      (0): SlimConv2d(\n",
      "        (_model): Sequential(\n",
      "          (0): ZeroPad2d((3, 4, 3, 4))\n",
      "          (1): Conv2d(3, 16, kernel_size=(8, 8), stride=(1, 1))\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): SlimConv2d(\n",
      "        (_model): Sequential(\n",
      "          (0): Conv2d(16, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (2): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (_value_branch_separate): Sequential(\n",
      "      (0): SlimConv2d(\n",
      "        (_model): Sequential(\n",
      "          (0): ZeroPad2d((3, 4, 3, 4))\n",
      "          (1): Conv2d(3, 16, kernel_size=(8, 8), stride=(1, 1))\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): SlimConv2d(\n",
      "        (_model): Sequential(\n",
      "          (0): Conv2d(16, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (2): SlimConv2d(\n",
      "        (_model): Sequential(\n",
      "          (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (post_fc_stack): FullyConnectedNetwork(\n",
      "    (_hidden_layers): Sequential(\n",
      "      (0): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=140, out_features=16, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_value_branch_separate): Sequential(\n",
      "      (0): SlimFC(\n",
      "        (_model): Sequential(\n",
      "          (0): Linear(in_features=140, out_features=16, bias=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_value_branch): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lstm): LSTM(24, 2, batch_first=True)\n",
      "  (_logits_branch): SlimFC(\n",
      "    (_model): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=8, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (_value_branch): SlimFC(\n",
      "    (_model): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# trainer.training_iteration()\n",
    "worker:ray.rllib.evaluation.rollout_worker.RolloutWorker= trainer.workers.local_worker()\n",
    "policy_spec = worker.policy_dict['agent_0']\n",
    "policy_instance = worker.policy_map['agent_0']\n",
    "nn_model:nn.Module = policy_instance.model \n",
    "print(dir(worker))\n",
    "# print(isinstance(nn_model,nn.Module))\n",
    "print(\"Total_params: \", sum([param.nelement() for param in nn_model.parameters()]))\n",
    "# print(nn_model.state_dict().keys())\n",
    "print(nn_model._modules.keys())\n",
    "print(nn_model)\n",
    "# print(\"Total_params: \", nn_model.total_parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
