{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 08:18:50,362\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-05-23 08:18:51,180\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-05-23 08:18:52.326970: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-23 08:18:53.453871: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-23 08:18:53.453935: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-23 08:18:53.453942: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\n",
      "2024-05-23 08:18:57,264\tWARNING deprecation.py:50 -- DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import ray\n",
    "\n",
    "\n",
    "from typing import *\n",
    "from ray import air\n",
    "from ray import tune\n",
    "from baselines.train.configs import get_experiment_config\n",
    "from ray.rllib.algorithms import ppo\n",
    "from ray.tune import registry\n",
    "from ray.air.integrations.wandb import WandbLoggerCallback\n",
    "from baselines.train import make_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 08:19:02,066\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2024-05-23 08:19:02,067\tWARNING algorithm_config.py:2548 -- Setting `exploration_config={'type': 'StochasticSampling'}` because you set `_enable_rl_module_api=False`. This exploration config was restored from a prior exploration config that was overriden when setting `_enable_rl_module_api=True`. This occurs because when RLModule API are enabled, exploration_config can not be set.\n",
      "2024-05-23 08:19:02,069\tWARNING algorithm_config.py:656 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "2024-05-23 08:19:02,074\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-05-23 08:19:05,014\tINFO worker.py:1612 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(pid=3188266)\u001b[0m 2024-05-23 08:19:14.507161: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/cv2/../../lib64:/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "\u001b[2m\u001b[36m(pid=3188266)\u001b[0m 2024-05-23 08:19:19.451324: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[2m\u001b[36m(pid=3188266)\u001b[0m 2024-05-23 08:19:19.451310: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/cv2/../../lib64:/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/cv2/../../lib64:\u001b[32m [repeated 61x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=3188265)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3188309)\u001b[0m 2024-05-23 08:19:22.138740: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=3188309)\u001b[0m 2024-05-23 08:19:22.138732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/cv2/../../lib64:/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/cv2/../../lib64:\u001b[32m [repeated 118x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=3188265)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=3188321)\u001b[0m \u001b[32m [repeated 51x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188269)\u001b[0m /NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188269)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(pid=3188326)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\u001b[32m [repeated 53x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188269)\u001b[0m 2024-05-23 08:19:47,258\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188269)\u001b[0m 2024-05-23 08:19:47,369\tINFO policy.py:1294 -- Policy (worker=3) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188269)\u001b[0m 2024-05-23 08:19:47,369\tINFO torch_policy_v2.py:113 -- Found 0 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188272)\u001b[0m 2024-05-23 08:19:47,385\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188272)\u001b[0m 2024-05-23 08:19:47,385\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188272)\u001b[0m         StateBufferConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188272)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188272)\u001b[0m 2024-05-23 08:19:47,385\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188272)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188272)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188272)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188272)\u001b[0m 2024-05-23 08:19:47,386\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188272)\u001b[0m 2024-05-23 08:19:47,386\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188272)\u001b[0m         StateBufferConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188272)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188272)\u001b[0m 2024-05-23 08:19:47,386\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188272)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188272)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188272)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188265)\u001b[0m 2024-05-23 08:19:47,525\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.tf.recurrent_net.LSTMWrapper` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188265)\u001b[0m 2024-05-23 08:19:47,526\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.complex_input_net.ComplexInputNetwork` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188265)\u001b[0m 2024-05-23 08:19:47,526\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188265)\u001b[0m 2024-05-23 08:19:47,526\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188265)\u001b[0m 2024-05-23 08:19:47,556\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.visionnet.VisionNetwork` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188265)\u001b[0m 2024-05-23 08:19:47,564\tWARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188265)\u001b[0m 2024-05-23 08:19:47,564\tWARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188265)\u001b[0m 2024-05-23 08:19:47,565\tWARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188265)\u001b[0m 2024-05-23 08:19:47,566\tWARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188265)\u001b[0m 2024-05-23 08:19:47,566\tWARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188265)\u001b[0m 2024-05-23 08:19:47,566\tWARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188265)\u001b[0m 2024-05-23 08:19:47,566\tWARNING deprecation.py:50 -- DeprecationWarning: `KLCoeffMixin` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188265)\u001b[0m 2024-05-23 08:19:47,570\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.recurrent_net.RecurrentNetwork` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3188265)\u001b[0m 2024-05-23 08:19:47,584\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=3188309)\u001b[0m \u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "2024-05-23 08:19:50,020\tINFO worker_set.py:297 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'INVENTORY': Box(-inf, inf, (2,), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (5, 5, 3), uint8)), Discrete(8)), 'agent_0': (Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'INVENTORY': Box(-inf, inf, (2,), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (5, 5, 3), uint8)), Discrete(8)), '__env__': (Dict('player_0': Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'INVENTORY': Box(-inf, inf, (2,), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (5, 5, 3), uint8)), 'player_1': Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'INVENTORY': Box(-inf, inf, (2,), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (5, 5, 3), uint8))), Dict('player_0': Discrete(8), 'player_1': Discrete(8)))}\n",
      "2024-05-23 08:19:50,452\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2024-05-23 08:19:50,463\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.tf.recurrent_net.LSTMWrapper` has been deprecated. This will raise an error in the future!\n",
      "2024-05-23 08:19:50,464\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.complex_input_net.ComplexInputNetwork` has been deprecated. This will raise an error in the future!\n",
      "2024-05-23 08:19:50,464\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!\n",
      "2024-05-23 08:19:50,465\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!\n",
      "2024-05-23 08:19:50,490\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.visionnet.VisionNetwork` has been deprecated. This will raise an error in the future!\n",
      "2024-05-23 08:19:50,503\tINFO policy.py:1294 -- Policy (worker=local) running on CPU.\n",
      "2024-05-23 08:19:50,504\tINFO torch_policy_v2.py:113 -- Found 2 visible cuda devices.\n",
      "2024-05-23 08:19:50,508\tWARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!\n",
      "2024-05-23 08:19:50,509\tWARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!\n",
      "2024-05-23 08:19:50,509\tWARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!\n",
      "2024-05-23 08:19:50,511\tWARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!\n",
      "2024-05-23 08:19:50,511\tWARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!\n",
      "2024-05-23 08:19:50,512\tWARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!\n",
      "2024-05-23 08:19:50,512\tWARNING deprecation.py:50 -- DeprecationWarning: `KLCoeffMixin` has been deprecated. This will raise an error in the future!\n",
      "2024-05-23 08:19:50,518\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.recurrent_net.RecurrentNetwork` has been deprecated. This will raise an error in the future!\n",
      "2024-05-23 08:19:50,531\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!\n",
      "2024-05-23 08:19:50,544\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2024-05-23 08:19:50,555\tINFO policy.py:1294 -- Policy (worker=local) running on CPU.\n",
      "2024-05-23 08:19:50,556\tINFO torch_policy_v2.py:113 -- Found 2 visible cuda devices.\n",
      "2024-05-23 08:19:50,569\tINFO util.py:118 -- Using connectors:\n",
      "2024-05-23 08:19:50,569\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2024-05-23 08:19:50,570\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2024-05-23 08:19:50,571\tINFO util.py:118 -- Using connectors:\n",
      "2024-05-23 08:19:50,571\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2024-05-23 08:19:50,571\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2024-05-23 08:19:50,572\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_1', 'agent_0']>\n",
      "2024-05-23 08:19:50,572\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2024-05-23 08:19:50,573\tINFO rollout_worker.py:550 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2024-05-23 08:19:50,736\tINFO trainable.py:172 -- Trainable.setup took 48.620 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2024-05-23 08:19:50,737\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "2024-05-23 08:19:50,919\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2024-05-23 08:19:50,920\tWARNING algorithm_config.py:2548 -- Setting `exploration_config={'type': 'StochasticSampling'}` because you set `_enable_rl_module_api=False`. This exploration config was restored from a prior exploration config that was overriden when setting `_enable_rl_module_api=True`. This occurs because when RLModule API are enabled, exploration_config can not be set.\n",
      "2024-05-23 08:19:51,065\tINFO trainable.py:904 -- Restored on 10.0.3.226 from checkpoint: results/torch/pd_matrix/PPO_meltingpot_397b4_00000_0_2024-05-21_13-58-39/checkpoint_007270\n",
      "2024-05-23 08:19:51,066\tINFO trainable.py:913 -- Current state after restoring: {'_iteration': 7270, '_timesteps_total': None, '_time_total': 44642.54804444313, '_episodes_total': 1452}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing training from results/torch/pd_matrix/PPO_meltingpot_397b4_00000_0_2024-05-21_13-58-39/checkpoint_007270\n"
     ]
    }
   ],
   "source": [
    "ckp = \"results/torch/pd_matrix/PPO_meltingpot_397b4_00000_0_2024-05-21_13-58-39/checkpoint_007270\"\n",
    "\n",
    "registry.register_env(\"meltingpot\", make_envs.env_creator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 08:22:08,602\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2024-05-23 08:22:08,603\tWARNING algorithm_config.py:2548 -- Setting `exploration_config={'type': 'StochasticSampling'}` because you set `_enable_rl_module_api=False`. This exploration config was restored from a prior exploration config that was overriden when setting `_enable_rl_module_api=True`. This occurs because when RLModule API are enabled, exploration_config can not be set.\n",
      "2024-05-23 08:22:08,609\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[2m\u001b[36m(pid=3233074)\u001b[0m 2024-05-23 08:22:12.892662: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/cv2/../../lib64:/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "\u001b[2m\u001b[36m(pid=3233114)\u001b[0m 2024-05-23 08:22:14.900160: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[2m\u001b[36m(pid=3233122)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3233191)\u001b[0m 2024-05-23 08:22:14.900841: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/cv2/../../lib64:/NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/cv2/../../lib64:\u001b[32m [repeated 179x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=3233191)\u001b[0m 2024-05-23 08:22:14.900866: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=3233114)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m /NAS2020/Workspaces/DRLGroup/wjxie/anaconda3/envs/gtp/lib/python3.10/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m 2024-05-23 08:22:31,688\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m 2024-05-23 08:22:31,744\tINFO policy.py:1294 -- Policy (worker=59) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m 2024-05-23 08:22:31,744\tINFO torch_policy_v2.py:113 -- Found 0 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m 2024-05-23 08:22:31,780\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m 2024-05-23 08:22:31,790\tINFO policy.py:1294 -- Policy (worker=59) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m 2024-05-23 08:22:31,790\tINFO torch_policy_v2.py:113 -- Found 0 visible cuda devices.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m 2024-05-23 08:22:31,804\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m 2024-05-23 08:22:31,804\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m         StateBufferConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m 2024-05-23 08:22:31,804\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m 2024-05-23 08:22:31,804\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m 2024-05-23 08:22:31,804\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m         StateBufferConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m 2024-05-23 08:22:31,804\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233201)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233074)\u001b[0m 2024-05-23 08:22:32,496\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.tf.recurrent_net.LSTMWrapper` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233074)\u001b[0m 2024-05-23 08:22:32,496\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.complex_input_net.ComplexInputNetwork` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233074)\u001b[0m 2024-05-23 08:22:32,496\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233074)\u001b[0m 2024-05-23 08:22:32,497\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233074)\u001b[0m 2024-05-23 08:22:32,596\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.visionnet.VisionNetwork` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233074)\u001b[0m 2024-05-23 08:22:32,605\tWARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233074)\u001b[0m 2024-05-23 08:22:32,605\tWARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233074)\u001b[0m 2024-05-23 08:22:32,605\tWARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233074)\u001b[0m 2024-05-23 08:22:32,606\tWARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233074)\u001b[0m 2024-05-23 08:22:32,606\tWARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233074)\u001b[0m 2024-05-23 08:22:32,606\tWARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233074)\u001b[0m 2024-05-23 08:22:32,606\tWARNING deprecation.py:50 -- DeprecationWarning: `KLCoeffMixin` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233074)\u001b[0m 2024-05-23 08:22:32,610\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.recurrent_net.RecurrentNetwork` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3233074)\u001b[0m 2024-05-23 08:22:32,627\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!\n",
      "2024-05-23 08:22:32,889\tINFO worker_set.py:297 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'INVENTORY': Box(-inf, inf, (2,), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (5, 5, 3), uint8)), Discrete(8)), 'agent_1': (Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'INVENTORY': Box(-inf, inf, (2,), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (5, 5, 3), uint8)), Discrete(8)), '__env__': (Dict('player_0': Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'INVENTORY': Box(-inf, inf, (2,), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (5, 5, 3), uint8)), 'player_1': Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'INVENTORY': Box(-inf, inf, (2,), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (5, 5, 3), uint8))), Dict('player_0': Discrete(8), 'player_1': Discrete(8)))}\n",
      "2024-05-23 08:22:32,896\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2024-05-23 08:22:32,909\tINFO policy.py:1294 -- Policy (worker=local) running on CPU.\n",
      "2024-05-23 08:22:32,910\tINFO torch_policy_v2.py:113 -- Found 2 visible cuda devices.\n",
      "2024-05-23 08:22:32,925\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2024-05-23 08:22:32,937\tINFO policy.py:1294 -- Policy (worker=local) running on CPU.\n",
      "2024-05-23 08:22:32,938\tINFO torch_policy_v2.py:113 -- Found 2 visible cuda devices.\n",
      "2024-05-23 08:22:32,952\tINFO util.py:118 -- Using connectors:\n",
      "2024-05-23 08:22:32,952\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2024-05-23 08:22:32,952\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2024-05-23 08:22:32,953\tINFO util.py:118 -- Using connectors:\n",
      "2024-05-23 08:22:32,953\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2024-05-23 08:22:32,954\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2024-05-23 08:22:32,954\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_1', 'agent_0']>\n",
      "2024-05-23 08:22:32,954\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2024-05-23 08:22:32,954\tINFO rollout_worker.py:550 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2024-05-23 08:22:33,084\tINFO trainable.py:172 -- Trainable.setup took 24.472 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2024-05-23 08:22:33,085\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n",
      "2024-05-23 08:22:33,246\tWARNING algorithm_config.py:2534 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2024-05-23 08:22:33,247\tWARNING algorithm_config.py:2548 -- Setting `exploration_config={'type': 'StochasticSampling'}` because you set `_enable_rl_module_api=False`. This exploration config was restored from a prior exploration config that was overriden when setting `_enable_rl_module_api=True`. This occurs because when RLModule API are enabled, exploration_config can not be set.\n",
      "2024-05-23 08:22:33,395\tINFO trainable.py:904 -- Restored on 10.0.3.226 from checkpoint: results/torch/pd_matrix/PPO_meltingpot_397b4_00000_0_2024-05-21_13-58-39/checkpoint_007270\n",
      "2024-05-23 08:22:33,396\tINFO trainable.py:913 -- Current state after restoring: {'_iteration': 7270, '_timesteps_total': None, '_time_total': 44642.54804444313, '_episodes_total': 1452}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing training from results/torch/pd_matrix/PPO_meltingpot_397b4_00000_0_2024-05-21_13-58-39/checkpoint_007270\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer:ppo.PPO = ppo.PPO.from_checkpoint(ckp)\n",
    "trainer.restore(ckp)\n",
    "print(f\"Continuing training from {ckp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO\n",
      "['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__ray_actor_class__', '__ray_ready__', '__ray_terminate__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_allow_unknown_configs', '_allow_unknown_subkeys', '_annotated', '_automatic_evaluation_duration_fn', '_before_evaluate', '_checkpoint_cls', '_checkpoint_info_to_algorithm_state', '_close_logfiles', '_compile_iteration_results', '_counters', '_create_checkpoint_dir', '_create_local_replay_buffer_if_necessary', '_create_logger', '_env_id', '_episode_history', '_episodes_to_be_collected', '_episodes_total', '_evaluate_async', '_export_model', '_get_env_id_and_creator', '_get_latest_available_checkpoint', '_get_latest_local_available_checkpoint', '_get_latest_remote_available_checkpoint', '_get_learner_bundles', '_implements_method', '_init', '_iteration', '_iterations_since_restore', '_kwargs_for_execution_plan', '_last_artifact_sync_iter', '_last_result', '_local_ip', '_logdir', '_maybe_load_artifacts_from_cloud', '_maybe_load_checkpoint_from_cloud', '_maybe_load_from_cloud', '_maybe_save_artifacts_to_cloud', '_maybe_save_to_cloud', '_monitor', '_open_logfiles', '_override_all_key_list', '_override_all_subkeys_if_type_changes', '_progress_metrics', '_record_usage', '_remote_storage_path', '_remote_worker_ids_for_metrics', '_restore_from_checkpoint_obj', '_restored', '_result_logger', '_run_offline_evaluation', '_run_one_evaluation', '_run_one_training_iteration', '_run_one_training_iteration_and_evaluation_in_parallel', '_should_create_evaluation_rollout_workers', '_should_upload_artifacts', '_start_time', '_stderr_context', '_stderr_file', '_stderr_fp', '_stderr_logging_handler', '_stderr_stream', '_stdout_context', '_stdout_file', '_stdout_fp', '_stdout_stream', '_sync_filters_if_needed', '_sync_weights_to_workers', '_time_since_restore', '_time_total', '_timers', '_timesteps_since_restore', '_timesteps_total', '_trial_info', 'add_policy', 'callbacks', 'cleanup', 'compute_actions', 'compute_single_action', 'config', 'default_resource_request', 'delete_checkpoint', 'env_creator', 'evaluate', 'evaluation_config', 'evaluation_dataset', 'evaluation_metrics', 'evaluation_workers', 'execution_plan', 'export_model', 'export_policy_checkpoint', 'export_policy_model', 'from_checkpoint', 'from_state', 'get_auto_filled_metrics', 'get_config', 'get_current_ip_pid', 'get_default_config', 'get_default_policy_class', 'get_policy', 'get_state', 'get_weights', 'import_model', 'import_policy_model_from_h5', 'is_actor', 'iteration', 'learner_group', 'load_checkpoint', 'local_replay_buffer', 'log_result', 'logdir', 'merge_algorithm_configs', 'remote_checkpoint_dir', 'remote_requests_in_flight', 'remove_policy', 'reset', 'reset_config', 'resource_help', 'restore', 'restore_from_object', 'restore_workers', 'reward_estimators', 'save', 'save_checkpoint', 'save_to_object', 'set_weights', 'setup', 'step', 'stop', 'sync_config', 'sync_num_retries', 'sync_sleep_time', 'train', 'train_buffered', 'train_exec_impl', 'training_iteration', 'training_step', 'trial_id', 'trial_name', 'trial_resources', 'uses_cloud_checkpointing', 'validate_config', 'validate_env', 'workers']\n",
      "{'_env_id': 'meltingpot', 'env_creator': <function env_creator at 0x7f191a67a290>, 'local_replay_buffer': None, '_timers': defaultdict(<class 'ray.util.timer._Timer'>, {}), '_counters': defaultdict(<class 'int'>, {'num_env_steps_sampled': 2908000, 'num_env_steps_trained': 2908000, 'num_agent_steps_sampled': 5816000, 'num_agent_steps_trained': 5816000}), '_episode_history': [], '_episodes_to_be_collected': [], 'evaluation_config': <ray.rllib.algorithms.ppo.ppo.PPOConfig object at 0x7f1b4ddc9960>, 'evaluation_workers': None, 'evaluation_metrics': {'evaluation': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan}}}, 'config': <ray.rllib.algorithms.ppo.ppo.PPOConfig object at 0x7f19199335b0>, '_result_logger': <ray.tune.logger.unified.UnifiedLogger object at 0x7f1919aa4550>, '_logdir': '/home/wjxie/ray_results/PPO_meltingpot_2024-05-23_08-22-08y4styowt', '_stdout_context': None, '_stdout_fp': None, '_stdout_stream': None, '_stderr_context': None, '_stderr_fp': None, '_stderr_stream': None, '_stderr_logging_handler': None, '_iteration': 7270, '_time_total': 44642.54804444313, '_timesteps_total': None, '_episodes_total': 1452, '_time_since_restore': 0.0, '_timesteps_since_restore': 0, '_iterations_since_restore': 0, '_last_result': None, '_restored': True, '_trial_info': None, '_stdout_file': None, '_stderr_file': None, '_start_time': 1716452528.612612, '_local_ip': '10.0.3.226', 'callbacks': <ray.rllib.algorithms.callbacks.DefaultCallbacks object at 0x7f1b540f3e50>, 'remote_requests_in_flight': defaultdict(<class 'set'>, {}), 'workers': <ray.rllib.evaluation.worker_set.WorkerSet object at 0x7f19198da230>, 'train_exec_impl': None, 'evaluation_dataset': None, 'reward_estimators': {}, 'learner_group': None, '_monitor': <UtilMonitor(Thread-9, started daemon 139750728103680)>, 'remote_checkpoint_dir': None, 'sync_config': SyncConfig(upload_dir=None, syncer=None, sync_period=300, sync_timeout=1800, sync_artifacts=True, sync_on_checkpoint=True), 'sync_num_retries': 3, 'sync_sleep_time': 1.0, '_last_artifact_sync_iter': None}\n"
     ]
    }
   ],
   "source": [
    "print(trainer)\n",
    "print(dir(trainer))\n",
    "print(trainer.__dict__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
